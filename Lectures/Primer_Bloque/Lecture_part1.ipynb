{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Primer Bloque`\n",
    "\n",
    "- Arquitectura de computadores\n",
    "- Errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores\n",
    "\n",
    "Usualmente en los libros en ingles aparecen dos definiciones *accuracy* y *precision*, en español ambas significarían lo mismo *precisión*. Sin embargo, comunmente la primera indicaría cuanto coincide el valor numérico con el valor verdadero (en muchos casos desconocido) y la segunda cuantos dígitos se usarán en una operación matemática, esto sin importar si estos dígitos son correctos o no. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si dejamos a un lado los errores de medición y humanos, típicamente en un código númerico tendremos que lidiar con dos tipos de errores:\n",
    "- los de Aproximación\n",
    "- los de Redondeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> `Errores de Aproximación`\n",
    "\n",
    "Para entender mejor este error, veamos un ejemplo. \n",
    "\n",
    "Intentemos aproximar una exponencial $y=e^{x}$ alrededor de x=0 usando una serie de Taylor: $\\sum_n^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^{n}$,\n",
    "$$y_{approx}=\\sum_n^{n_{max}}\\frac{x^2}{n!}. $$\n",
    "\n",
    "Como se enuncia en el Teorema de Taylor, $y_{approx}=y$ en el límite cuando $n_{max}\\to \\infty$, en cualquier otro caso lo que estamos haciendo es aproximar la exponencial hasta los términos correspondientes a $n_{max}$ considerado y descartar los restantes ($n_{max}+1$ hasta $\\infty$). Entonces, `en principio`, con el simple coste de considerar $n_{max}$ grandes, se puede obtener una mejor aproximación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> `Errores de redondeo`\n",
    "\n",
    "Este tipo de errores aparecen cada vez que realizamos un cálculo usando números con cifras decimales, y es una consecuencia de no tener una precisión infinita, lo que hace que se \"pierda\" parte de la información. Veamos un ejemplo:\n",
    "\n",
    "- Usando cálculo básico sabemos que esta igualdad es cierta $(\\sqrt{2})^2-2=0$, sin embargo, si realizamos esta operación numéricamente veremos que no es así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "print((2**(1/2))**2-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que ocurre es que $\\sqrt{2}$ no puede ser evaluado con infinítos dígitos y por lo tanto resulta \"ligeramente\" inexacto su resultado, y este es el que se utiliza para la próxima operación propagándose el error y ocurriendo lo que se conoce como error de redondeo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Absoluto y Relativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Error absoluto`: Supongamos que se está estudiando una cierta cantidad cuyo valor exacto es $x_0$. Si $x$ es una aproximación de este, entonces se define el error absoluto como:\n",
    "\\begin{equation}\n",
    "\\triangle x:=|x-x_0|\n",
    "\\end{equation}\n",
    "La fuente de este error absoluto puede ser debido a la incertidumbre en los datos, un error de redondeo o de aproximación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No especificamos en este punto la fuente de este error absoluto: podrían ser incertidumbres en los datos de entrada, una inexactitud introducida por nuestro imperfecto cálculo anterior o el resultado de un error de redondeo (posiblemente acumulado en varios cálculos). \n",
    "\n",
    "Usualmente a partir de este error se puede definir un límite:\n",
    "$$|\\triangle x|=|x-x_0|\\leq \\epsilon$$\n",
    "donde $\\epsilon$ debe ser lo más pequeño posible. \n",
    "\n",
    "A partir de este límite uno puede reportar hasta donde sus resultados son correctos:\n",
    "$$x-\\epsilon \\leq x_0 \\leq x+\\epsilon$$\n",
    "\n",
    "Esto significa que, aunque no conocemos el valor exacto de $x_0$, sí sabemos que podría ser como máximo $x+\\epsilon \\leq$ y como mínimo $x-\\epsilon \\leq$. Usualmente este límite es escrito como $x_0=x\\pm \\epsilon$. IMPORTANTE: en ocasiones el $\\epsilon$ que se usa no es el definido anteriormente, sino la desviación estandar, lo que es aplicado cuando se tiene un conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AHORA, ven algún error en este tipo de error. ¿Qué sería un error absoluto pequeño?\n",
    "\n",
    "Veamos unos ejemplos:\n",
    "\n",
    "- Consideremos el valor real $x_0 = 1.000$ y el aproximado $x=0.999$, esto nos da un error absoluto $\\triangle x_{caso1}=10^{-3}$. Bastante pequeño ¿no?\n",
    "\n",
    "- Consideremos ahora el valor real $x_0= 1\\, 000\\, 000\\, 000.0$ y la aproximación $x= 999\\, 999\\,999.0$, esto nos da un error absoluto de $\\triangle x_{caso2}=1$.\n",
    "\n",
    "Si comparamos el error absoluto de ambos ejemplos uno (sin conocer el valor real) podría estar tentado a pensar que el primer caso es una mejor aproximación que el último. Notar que el error absoluto del último es ridiculamente más grande (3 ordenes de magnitud). Sin embargo, como se aprecia el valor aproximado no está tan lejos del real. Entonces para comparar aproximaciones de diferentes escalas el error absoluto no es un buen medidor. \n",
    "\n",
    "- `Error relativo`: En los casos que se desea comparar aproximaciones en diferentes escalas se recomienda usar el error relativo:\n",
    "$$\\delta x :=\\frac{\\triangle x}{x_0}=\\frac{|x-x_0|}{|x_0|}$$ \n",
    "\n",
    "Si repetimos los cálculos para los ejemplos anteriores tendremos que: $\\delta x_{caso1}=10^{-3}$, mientras que $\\delta x_{caso2}=10^{-9}$. Siendo el segundo caso una mejor aproximación: el primero representa un $0.1\\%$ respecto al valor real, mientras que el segundo $10^{-7} \\%$.\n",
    "\n",
    "Para este tipo de error se define el límite como:\n",
    "$$|\\delta x| :=\\bigg|\\frac{\\triangle x}{x}\\bigg|\\leq \\epsilon$$ \n",
    "\n",
    "COMENTARIOS:\n",
    "\n",
    "- En ocasiones no conocemos el valor exacto, por lo que es más conveniente utilizar en el denominador el valor aproximado.\n",
    "\n",
    "- Este tipo de error no es adecuado cuando el valor exacto es $x_0=0$ (o muy cercano a cero). En estos casos suele utilizarse \n",
    "$$\\delta x :=\\frac{|x-x_0|}{1+|x_0|}$$ \n",
    "\n",
    "Lo cual no es del todo correcto ya que no representa una diferencia relativa pues no cumple la propiedad de rescalamiento: $d(x, x_0)=d(\\lambda x, \\lambda x_0)$. Es decir, no se le puede llamar error relativo.\n",
    "\n",
    "En estos casos se ha de utilizar otros tipos de errores relativos como por ejemplo: \n",
    "\n",
    "- [Relative Percent Difference (PRD)](https://en.wikipedia.org/wiki/Relative_change):\n",
    "$$\\delta x :=2\\frac{x-x_0}{|x|+|x_0|}$$ \n",
    "\n",
    "\n",
    "- [Relative Change and Difference](https://en.wikipedia.org/wiki/Relative_change):\n",
    "$$\\delta x :=\\frac{|x-x_0|}{\\max{(x, x_0)}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagación de Errores:\n",
    "\n",
    "- `Suma o Resta`\n",
    "\n",
    "Supongamos que queremos obtener el resultado de la siguiente operación: $x_0=a_0-b_0$. Sin embargo no conocemos estos valores exactos, sinó sus aproximados $a, b$ con sus respectivos errores absolutos $\\triangle a, \\triangle b$. El error absoluto de la operación será:\n",
    "$$|\\triangle x|\\leq|\\triangle a|+|\\triangle b|$$\n",
    "\n",
    "donde el más es debido a que es el límite superior. El resultado anterior es válido para ambas operaciones.\n",
    "\n",
    "- `Multiplicación o División`\n",
    "\n",
    "Similar al caso anterior se puede probar que el error de la operación $x=a\\times b$ será:\n",
    "$$|\\delta x|\\leq|\\delta a|+|\\delta b|$$\n",
    "\n",
    "- `Propagación del error en funciones de una variable`\n",
    "\n",
    "Suponiéndose que se tiene una función $f(x)$ y se quiere calcular su valor $y=f(x)$, se puede probar que en error absoluto sería:\n",
    "$$\\triangle y\\approx \\bigg|\\frac{d f(x)}{dx}\\bigg|\\triangle x$$\n",
    "\n",
    "mientras que el Relativo es:\n",
    "$$\\delta y=\\frac{\\triangle y}{y}\\approx \\frac{x}{f(x)}\\bigg|\\frac{d f(x)}{dx}\\bigg|\\delta x$$\n",
    "\n",
    "- `Generalización a varias variables`\n",
    "\n",
    "Error absoluto:\n",
    "$$\\triangle y\\approx \\sum_i\\bigg|\\frac{d f}{dx_i}\\bigg|\\triangle x_i$$\n",
    "\n",
    "Error relativo:\n",
    "$$\\delta y\\approx \\sum_i \\frac{x_i}{f}\\bigg|\\frac{d f}{dx_i}\\bigg|\\delta x_i$$\n",
    "\n",
    "NOTAR como se recuperan las fórmulas anteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación de número reales\n",
    "\n",
    "Las computadoras codifican toda la información en binario, o lo que es lo mismo, en dígito o bit: los bits `sólo pueden tomar dos valores posibles, por convención 0 o 1`. Los números se almacenan en forma binaria, es decir, como colecciones de $0$ y $1$. Por ejemplo, los números reales se almacenen mediante representación de punto flotante. Esto tiene la forma general:\n",
    "$$\\pm \\, \\text{mantissa} \\times 10^{\\text{exponente}}$$\n",
    "\n",
    "Ahora, debido a que la computadora solo puede almacenar un número finito de bits, esta tendrá un límite, una `precisión de máquina` (no es más que el número de decimales que puede almacenar usando la representación del punto flotante). Estos vienen en dos variedades: `números normales` y `subnormales`. Existiendo tres formas de perder presición numérica:\n",
    "- underflow: ocurre para números muy pequeños.\n",
    "- overflow: ocurre para números muy grandes.\n",
    "- rounding: ocurre para números decimales cuyo valor se encuentra entre dos números exactamente representables.\n",
    "\n",
    "<img src=\"capturas/1.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En particular `Python` emplea *doble precisión* para el caso de los número flotantes. En estos casos su almacenamiento es de $64$ bits en total. Es decir, puede almacenar números desde:\n",
    "$$\\pm 4.9\\times10^{-324} \\leftrightarrow \\pm 1.8\\times 10^{308}$$\n",
    "\n",
    "La mayor parte de esta capacidad de almacenamiento se encuentra en el término correspondiente al exponente. En este caso para los doble precisión si intentamos representar un número menor a $4.9\\times10^{-324}$ ocurre un *underflow*, mientras que uno mayor que $1.8\\times 10^{308}$ conllevaría a un *overflow*.\n",
    "\n",
    "IMPORTANTE: Hay que tener en cuenta que poder representar $4.9\\times10^{-324}$ no significa que seamos capaces de almacenar $324$ cifras significativas en un doble precisión. El número de cifras significativas (y el concepto relacionado de precisión) se encuentra en el coeficiente (mantissa). Por ejemplo $1.8$ o $1.234567$. Para los doble precisión el número de cifras significativas es $1$ parte en $2^{52}$, es decir $1/2^{52}\\approx 2.2\\times10^{-16}$, lo que equivale a $15$ o $16$ dígitos decimales.\n",
    "\n",
    "Veamos unos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$2\\times 10^{298}$ ->  2e+298\n",
      "$2\\times 10^{300}$ ->  inf\n",
      "$2\\times 10^{302}$ ->  inf\n"
     ]
    }
   ],
   "source": [
    "# Overflow\n",
    "\n",
    "k = 298  # 303\n",
    "large = 2.*10**(k)\n",
    "for _ in range(3):\n",
    "    print(r'$2\\times 10^{%d}$ -> '%k, large)\n",
    "    k += 2\n",
    "    large *=10**k    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión de máquina \n",
    "\n",
    "¿Saben que es la precisión de máquina?\n",
    "\n",
    "La precisión de máquina no está relacionado con los número que podamos representar, sinó con la distancia entre dos líneas verticales en la figura anterior. Como se comentó, cualquier número entre las dos líneas se redondea, ya sea hacia la izquierda o hacia la derecha.\n",
    "\n",
    "Al realizar operaciones aritméticas con dos números de punto flotante y el resultado no es un número de punto flotante exactamente representable (por ejemplo: 1 y 10 se pueden representar, pero 1/10 no), entra en juego la precisión de máquina. \n",
    "\n",
    "\n",
    "Pasamos ahora a la cuestión de realizar operaciones aritméticas utilizando tales números: esto da lugar a la importante cuestión del redondeo. Esta pregunta surge cada vez que intentamos combinar dos números de punto flotante pero la respuesta no es un número de punto flotante exactamente representable.\n",
    "\n",
    "Veamos un ejemplo ficticio para entender mejor. Consideremos que solo podemos almacener 5 cifras significativas (dígitos). Supongamos que queremos sumar los números $0.12345$ y $1.2345$. Se podría intentar llevarlo a la notación de punto flotante, es decir $1.2345 = 0.12345 \\times 10^{1}$ mientras que $0.12345 = 0.12345 \\times 10^{0}$. Ahora, en nuestro sistema, estos dos números tendrían la misma mantisa y diferentes exponentes. Sin embargo, para sumar dos mantisas tenemos que tener los mismo exponente, por ende esta opción no es viable y debemos realizar la operación como números reales (es decir, no números decimales de cinco dígitos):\n",
    "\n",
    "$$0.12345 + 1.2345 = 1.35795$$\n",
    "\n",
    "Ahora, si notan, la respuesta contiene seis dígitos decimales, $1.35795$. Dado que estamos limitados a números decimales de cinco dígitos, esto nos deja con la opción de reducir el resultado a $1.3579$ o redondearlo a $1.3580$. Lo cual nos llevaría a perder precisión.\n",
    "\n",
    "En resumen, la precisión de máquina $e_{m}$, se define como el número más pequeño en punto flotante que, sumando al 1.0, produce un resultado diferente de 1.0. Usualmente para un doble precisión es de $e_{m}\\approx 2.2\\times10^{-16}$, y para un flotante $e_{m}\\approx 1.2\\times10^{-7}$.\n",
    "\n",
    "Ejemplo: Calculemos la precisión de máquina comenzamos con un número pequeño y lo vamos reduciendo a la mitad, después de lo cual lo sumamos a $1.0$ y así sucesivamente hasta que eventualmente obtendremos el gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ->  1.0000000000000004 4.440892098500626e-16\n",
      "1  ->  1.0000000000000002 2.220446049250313e-16\n",
      "2  ->  1.0 1.1102230246251565e-16\n",
      "3  ->  1.0 5.551115123125783e-17\n"
     ]
    }
   ],
   "source": [
    "# precisión de máquina\n",
    "small = 1/2**50\n",
    "for i in range(4):\n",
    "    small /= 2\n",
    "    print(i, ' -> ', 1+small, small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTESE como aún siendo doble precisión (puede almacenar números tan pequeños como $10^{-300}$), no significa que pueda almacenar $1+10^{-300}$ ya que esto necesitarías 301 dígitos de precisión (y todo lo que tienes es 16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`La resta`\n",
    "\n",
    "Hagamos un paréntesis y analicemos que ocurre en una resta:\n",
    "\n",
    "    - la pérdida de cifras significativas al restar dos números casi iguales\n",
    "\n",
    "    - la pérdida de aún más dígitos al realizar la resta utilizando números de punto flotante (que tienen precisión finita). \n",
    "\n",
    "Empecemos por el primer caso. Resta dos números casi iguales, cada uno de los cuales tiene 20 cifras significativas:\n",
    "$$1.2345678912345678912−1.2345678900000000000 = 0.0000000012345678912$$\n",
    "\n",
    "Note que al restar número reales (no representaciones de punto flotante) terminamos con 11 cifras significativas, aunque estamos tratando con números reales/precisión infinita perdimos precisión. Ahora, analicemos el segundo caso, y utilicemos la representación de coma flotante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.234568003383174e-09"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2345678912345678912 - 1.2345678900000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con la respuesta que teníamos arriba (para números reales), vemos que solo coinciden en las primeras 6 (de 11) cifras significativas. Esto se debe en parte al hecho de que cada uno de nuestras entradas no se representan en el ordenador utilizando las 20 cifras significativas completas, sino sólo 16 dígitos como máximo. Explícitamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.234567891234568, 1.23456789)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2345678912345678912, 1.2345678900000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto muestra que perdemos precisión en el primer número, lo que luego conduce a una pérdida de precisión en el resultado de la resta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando flotantes\n",
    "\n",
    "Dado que sólo cierto números se pueden representar exactamente como flotantes (otros números se redondean al número de máquina más cercano), debemos tener cuidado al comparar números de punto flotante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = 0.1 + 0.2\n",
    "yt = 0.3\n",
    "\n",
    "xt == yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿qué paso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30000000000000004, 0.3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt, yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una posible solución para realizar esta igualdad de variables de punto flotante es tomar el valor absoluto de su diferencia y verificar si esta es menor que algún humbral aceptable por ejemplo: $10^{-10}-10^{-12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(xt-yt)<1.e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La metodología comentada (denominada *absulute epsilon*) es adecuada en muchas ocasiones donde el \"tamaño\" de los números es \"natural\". Sin embargo, hay situaciones donde puede darnos resultados erroneos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0010013580322265625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = 12345678912.345\n",
    "yt = 12345678912.346\n",
    "print(xt-yt)\n",
    "\n",
    "abs(xt-yt)<1.e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución para este caso es usar una diferencia relativa (*relative epsilon*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxFin = lambda x, y: max(abs(x), abs(y))\n",
    "\n",
    "abs(xt-yt)/maxFin(xt, yt)<1.e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma compensada\n",
    "\n",
    "Pasamos ahora a una cuestión crucial relativa a las operaciones con flotadores; En resumen, debido a errores de redondeo, cuando se trata de números de punto flotante, `la ley asociativa del álgebra no necesariamente se cumple`. \n",
    "\n",
    "Usted sabe que $0.1+0.2=0.3$ sin embargo, este resultado puede depender del orden en que se lleva a cabo las operaciones si usamos números de puntos flotantes.\n",
    "\n",
    "Veamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0999999999999999\n",
      "1.1\n"
     ]
    }
   ],
   "source": [
    "res1 = (0.7 + 0.1) + 0.3\n",
    "res2 = 0.7 + (0.1 + 0.3)\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este ejemplo queda claro que operaciones que son equivalentes en números reales pueden no serlo si se usan flotantes. Este ejemplo no es atípico, de hecho, puede ocurrír más drástico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "xt = 1.e20\n",
    "yt = -1.e20\n",
    "zt = 1.\n",
    "\n",
    "res1 = (xt + yt) + zt\n",
    "res2 = xt + (yt + zt)\n",
    "\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En el primer caso, los dos números grandes, `xt`, `yt`, se cancelan entre sí y nos queda la unidad como respuesta. \n",
    "- En el segundo caso, nos enfrentamos a una situación similar a la discutida en la precisión de máquina, sumar $1$ al número grande (negativo) `yt` simplemente se redondea a `yt`, luego, se cancela con `xt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar el error garrafal viene del hecho de estar trabajando con magnitudes muy diferentes (muy grandes y muy pequeños) y con signos opuestos. Uno podría decir entonces que cuando esto ocurre no se puede confiar en el resultado numérico. Sin embargo, en muchas ocasiones no somos concientes de que esto ocurre (ya que puede aparecer internamente en operaciones intermedias). En tal sentido `la lección es que uno debe acostumbrarse a razonar sobre sus cálculos, en lugar de confiar ciegamente en lo que produce la computadora`.\n",
    "\n",
    "\n",
    "A continuación veamos como podemos intentar resolver estos problemas. Una manera de evitar estos errores de redondeo es `ordenar los números y luego sumarlos comenzando por el más pequeño`. Sin embargo, hay escenarios en que esto no es viable, en estos casos se emplea un truco llamado `suma compensada` o `suma Kahan`. Este truco lo que hace es estimar el error de redondeo en cada suma y luego compensarlo con un término de corrección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0999999999999999 1.1\n"
     ]
    }
   ],
   "source": [
    "def kahansum(lis):\n",
    "    s, e = 0., 0.\n",
    "    for x in lis:\n",
    "        temp = s\n",
    "        y = x + e\n",
    "        s = temp + y \n",
    "        e = (temp - s) + y\n",
    "    return s\n",
    "\n",
    "lis = [0.7, 0.1, 0.3]\n",
    "print(sum(lis), kahansum(lis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de Kahan requiere más cálculos que la suma regular lo cual penaliza el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando expresiones\n",
    "\n",
    "A continuación se discutirá como es posible perder precisión como consecuencia de la forma en que se escriben las ecuaciones. Por ejemplo consideremos:\n",
    "$$f(x)=\\frac{1}{\\sqrt{x^2+1}-x}$$\n",
    "\n",
    "para valores grandes de $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -> 19999.99977764674\n",
      "100000 -> 200000.22333140278\n",
      "1000000 -> 1999984.77112922\n",
      "10000000 -> 19884107.85185185\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "f = lambda x: 1/(np.sqrt(x**2+1)-x)\n",
    "\n",
    "xs = [10**i for i in range(4, 8)]\n",
    "ys = [f(i) for i in xs]\n",
    "\n",
    "for x, y in zip(xs, ys):\n",
    "    print(x, '->',  y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten como el resultado parece empeorar cada vez más a medida que aumenta el valor de x. Una manera de verlo es considerando $x=10^{8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/bkm6rtjj0f104l91yr9n6t2c0000gn/T/ipykernel_74027/577568385.py:2: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f = lambda x: 1/(np.sqrt(x**2+1)-x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sucede porque para valores grandes de $x$, sabemos que $x + 1 \\approx x$, lo que implica que necesitemos evaluar la raíz cuadrada con mucha precisión si quiero poder restarle un número casi igual.\n",
    "\n",
    "Una forma sencilla de evitar este problema consiste en reescribir la expresión inicial como:\n",
    "$$ f(x)=\\sqrt{x^2+1}+x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -> 20000.000050000002\n",
      "100000 -> 200000.00000499998\n",
      "1000000 -> 2000000.0000005001\n",
      "10000000 -> 20000000.000000052\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "f = lambda x: np.sqrt(x**2+1)+x\n",
    "\n",
    "xs = [10**i for i in range(4, 8)]\n",
    "ys = [f(i) for i in xs]\n",
    "\n",
    "for x, y in zip(xs, ys):\n",
    "    print(x, '->',  y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten como mejoró. De hecho, como se aprecia de la ecuación para $x$ grandes la función se comporta como $2x$. \n",
    "\n",
    "Resumiendo, en muchas ocasiones una simple reescritura de la expresión inicial puede evitar problemas de precisión numérica (a menudo evitando una resta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea:\n",
    "1- \n",
    "\n",
    "<img src=\"capturas/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-\n",
    "\n",
    "<img src=\"capturas/3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
