{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Primer Bloque`\n",
    "\n",
    "- Errores\n",
    "- Tipos de errores\n",
    "- Error Real, Absoluto y Relativo\n",
    "- Propagación de errores\n",
    "- Representación de número reales. Comparando flotantes. Suma compensada\n",
    "- Manipulando expresiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errores\n",
    "\n",
    "Usualmente, en los libros en inglés aparecen dos definiciones: *accuracy* y *precision*. En español, ambas suelen traducirse como *precisión*. Sin embargo, comúnmente la primera se refiere a `cuán cercano está un valor numérico al valor verdadero` (que en muchos casos es desconocido), mientras que la segunda indica `cuántos dígitos se utilizan en una operación matemática`, independientemente de si dichos dígitos son correctos o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de Errores\n",
    "\n",
    "Si dejamos de lado los errores de medición y los errores humanos, típicamente en un código numérico tendremos que lidiar con dos tipos de errores:\n",
    "\n",
    "- errores de aproximación;\n",
    "\n",
    "- errores de redondeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> `Errores de Aproximación`\n",
    "\n",
    "Para entender mejor este tipo de error, veamos un ejemplo.\n",
    "\n",
    "Intentemos aproximar la función exponencial $y = e^{x}$ alrededor de $x = 0$ usando una serie de Taylor: \n",
    "\\begin{align}\n",
    "\\sum_n^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^{n},\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "En este caso, la aproximación queda:\n",
    "\n",
    "\\begin{align}\n",
    "y_{approx}=\\sum_n^{n_{max}}\\frac{x^n}{n!}.\n",
    "\\end{align}\n",
    "\n",
    "Como se enuncia en el Teorema de Taylor, $y_{\\text{approx}} = y$ en el límite cuando $n_{\\max} \\to \\infty$. En cualquier otro caso, lo que estamos haciendo es aproximar la exponencial considerando únicamente los términos hasta $n_{\\max}$ y descartando los restantes (desde $n_{\\max}+1 hasta \\infty$).\n",
    "\n",
    "Entonces, en principio, aumentando el valor de $n_{\\max}$ se puede obtener una mejor aproximación, a costa de un mayor esfuerzo computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver Ejemplo_1_Lect1.nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> `Errores de redondeo`\n",
    "\n",
    "Este tipo de errores aparece cada vez que realizamos cálculos utilizando números con cifras decimales y es consecuencia de no disponer de una precisión infinita. Como resultado, parte de la información numérica se *pierde* en cada operación.\n",
    "\n",
    "Veamos un ejemplo sencillo. Desde el punto de vista del cálculo exacto, sabemos que la igualdad:\n",
    "\n",
    "\\begin{align}\n",
    "(\\sqrt{2})^2-2=0,\n",
    "\\end{align}\n",
    "\n",
    "es cierta. Sin embargo, si realizamos esta operación numéricamente, observamos que el resultado no es exactamente cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "print((2**(1/2))**2-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto ocurre porque $\\sqrt{2}$ no puede representarse con infinitos dígitos en la computadora y, por lo tanto, su valor es solo una aproximación. Este valor aproximado se utiliza en la operación siguiente, propagando el error y dando lugar a lo que se conoce como **error de redondeo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Real, Absoluto y Relativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Error real`: Supongamos que se está estudiando una cierta cantidad cuyo valor exacto es $x_0$. Si $x$ es una aproximación de dicho valor, se define el error real como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\triangle_r x:=x-x_0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Error absoluto`: Bajo las mismas suposiciones, el error absoluto se define como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\triangle x:=|\\triangle_r x|=|x-x_0|\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este punto no se ha especificado el origen del `error absoluto`. Este puede provenir de incertidumbres en los datos, de inexactitudes introducidas por el método de cálculo utilizado o del efecto acumulado de errores de redondeo en varias operaciones.\n",
    "\n",
    "Usualmente, a partir del error absoluto se puede establecer una cota:\n",
    "\n",
    "\\begin{align}\n",
    "|\\triangle x|=|x-x_0|\\leq \\varepsilon,\n",
    "\\end{align}\n",
    "donde $\\varepsilon$ debe ser lo más pequeño posible. \n",
    "\n",
    "A partir de esta cota, se puede indicar el intervalo dentro del cual se encuentra el valor exacto:\n",
    "\n",
    "\\begin{align}\n",
    "x - \\varepsilon \\leq x_0 \\leq x + \\varepsilon.\n",
    "\\end{align}\n",
    "\n",
    "Esto significa que, aunque no conocemos el valor exacto de $x_0$, sabemos que este se encuentra entre $x - \\varepsilon$ y $x + \\varepsilon$. Usualmente, este resultado se expresa de forma compacta como:\n",
    "\\begin{align}\n",
    "x_0 = x \\pm \\varepsilon.\n",
    "\\end{align} \n",
    "\n",
    "**IMPORTANTE**: En algunos contextos, el valor de $\\varepsilon$ no corresponde al error absoluto definido anteriormente, sino a la desviación estándar, lo cual es habitual cuando se trabaja con conjuntos de datos experimentales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AHORA: `¿Qué sería un error absoluto pequeño?`\n",
    "\n",
    "Veamos algunos ejemplos:\n",
    "\n",
    "- Consideremos el valor real $x_0 = 1.000$ y el valor aproximado $x = 0.999$. En este caso, el error absoluto es:\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta x_{\\text{caso 1}} = 10^{-3}.\n",
    "\\end{align} \n",
    "\n",
    "A primera vista, este error parece bastante pequeño.\n",
    "\n",
    "- Consideremos ahora el valor real $x_0 = 1\\,000\\,000\\,000.0$ y la aproximación $x = 999\\,999\\,999.0$. En este caso, el error absoluto es\n",
    "\\begin{align}\n",
    "\\Delta x_{\\text{caso 2}} = 1.\n",
    "\\end{align} \n",
    "\n",
    "Si comparamos únicamente los errores absolutos de ambos ejemplos (sin conocer el valor real), uno podría verse tentado a pensar que el primer caso es una mejor aproximación que el segundo, ya que el error absoluto del segundo es considerablemente mayor (tres órdenes de magnitud).\n",
    "\n",
    "Sin embargo, si se observa la escala de los valores involucrados, se aprecia que en el segundo caso el valor aproximado no está realmente lejos del valor real. Esto muestra que, al comparar aproximaciones en diferentes escalas, el error absoluto no es un buen indicador de la calidad de la aproximación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Error relativo`: Cuando se desea comparar aproximaciones correspondientes a valores de distintas magnitudes, es preferible utilizar el error relativo, definido como:\n",
    "\n",
    "\\begin{align}\n",
    "\\delta x :=\\frac{\\triangle x}{x_0}=\\frac{|x-x_0|}{|x_0|}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Si repetimos los cálculos para los ejemplos anteriores, obtenemos:\n",
    "\\begin{align}\n",
    "\\delta x_{\\text{caso 1}} = 10^{-3}, \\qquad \\delta x_{\\text{caso 2}} = 10^{-9}.\n",
    "\\end{align}\n",
    "\n",
    "Esto indica que el segundo caso es una mejor aproximación: el primer error corresponde a un $0.1\\%$ del valor real, mientras que el segundo corresponde a $10^{-7}\\%$.\n",
    "\n",
    "\n",
    "Para este tipo de error suele definirse una cota:\n",
    "\n",
    "\\begin{align}\n",
    "|\\delta x| :=\\bigg|\\frac{\\triangle x}{x}\\bigg|\\leq \\epsilon\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMENTARIOS**:\n",
    "\n",
    "- \tEn muchas situaciones el valor exacto $x_0$ no es conocido. En esos casos, resulta más conveniente utilizar el valor aproximado en el denominador:\n",
    "\\begin{align}\n",
    "\\delta x := \\left|\\frac{x - x_0}{x}\\right|.\n",
    "\\end{align}\n",
    "\n",
    "- El error relativo no es adecuado cuando el valor exacto es $x_0 = 0$ (o muy cercano a cero). En estos casos, a veces se utiliza la expresión:\n",
    "\\begin{align}\n",
    "\\delta x := \\frac{|x - x_0|}{1 + |x_0|}.\n",
    "\\end{align}\n",
    "\n",
    "No obstante, esta cantidad no es estrictamente un error relativo, ya que no cumple la propiedad de reescalamiento:\n",
    "\\begin{align}\n",
    "d(x, x_0) = d(\\lambda x, \\lambda x_0),\n",
    "\\end{align}\n",
    "por lo que no puede interpretarse como una diferencia relativa en sentido estricto.\n",
    "\n",
    "En estos casos, es preferible utilizar otras medidas de diferencia relativa, por ejemplo:\n",
    "\n",
    "- [Relative Percent Difference (PRD)](https://en.wikipedia.org/wiki/Relative_change):\n",
    "\\begin{align}\n",
    "\\delta x :=2\\frac{x-x_0}{|x|+|x_0|}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- [Relative Change and Difference](https://en.wikipedia.org/wiki/Relative_change):\n",
    "\\begin{align}\n",
    "\\delta x :=\\frac{|x-x_0|}{\\max{(x, x_0)}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagación de Errores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Suma o Resta`\n",
    "\n",
    "Supongamos que queremos obtener el resultado de la operación:\n",
    "\\begin{align}\n",
    "x_0 = a_0 - b_0.\n",
    "\\end{align}\n",
    "Sin embargo, no conocemos los valores exactos $a_0$ y $b_0$, sino sus aproximaciones $a$ y $b$, con errores absolutos $\\Delta a$ y $\\Delta b$, respectivamente.\n",
    "\n",
    "El error absoluto de la operación satisface:\n",
    "\\begin{align}\n",
    "|\\Delta x| \\leq |\\Delta a| + |\\Delta b|.\n",
    "\\end{align}\n",
    "\n",
    "El signo `+` aparece porque estamos considerando una cota superior del error. Este resultado es válido tanto para la suma como para la resta y puede demostrarse de manera directa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Multiplicación o División`\n",
    "\n",
    "De forma análoga, puede demostrarse que, para la operación\n",
    "\\begin{align}\n",
    "x = a \\times b \\quad \\text{(o } x = a / b\\text{)},\n",
    "\\end{align}\n",
    "\n",
    "el error relativo satisface la desigualdad:\n",
    "\\begin{align}\n",
    "|\\delta x| \\leq |\\delta a| + |\\delta b|.\n",
    "\\end{align}\n",
    "\n",
    "Esto muestra que, en productos y cocientes, los errores relativos se combinan de manera aproximadamente aditiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Propagación del error en funciones de una variable`\n",
    "\n",
    "Supongamos que se tiene una función $y = f(x)$ y que el valor de $x$ contiene un error absoluto $\\Delta x$. Entonces, para errores pequeños, el error absoluto en $y$ puede aproximarse por:\n",
    "\\begin{align}\n",
    "\\Delta y \\approx \\left|\\frac{d f(x)}{d x}\\right| \\Delta x.\n",
    "\\end{align}\n",
    "\n",
    "El error relativo correspondiente es:\n",
    "\\begin{align}\n",
    "\\delta y = \\frac{\\Delta y}{y} \\approx \\frac{x}{f(x)} \\left|\\frac{d f(x)}{d x}\\right| \\delta x.\n",
    "\\end{align}\n",
    "\n",
    "Estas expresiones se obtienen a partir de una aproximación lineal de la función alrededor del valor considerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Generalización a varias variables`\n",
    "\n",
    "Si la función depende de varias variables: $y = f(x_1, x_2, \\dots, x_n)$, y cada variable $x_i$ tiene un error absoluto $\\Delta x_i$, entonces el error absoluto total puede aproximarse por:\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta y \\approx \\sum_i \\left|\\frac{\\partial f}{\\partial x_i}\\right| \\Delta x_i.\n",
    "\\end{align}\n",
    "\n",
    "De manera análoga, el error relativo queda:\n",
    "\\begin{align}\n",
    "\\delta y \\approx \\sum_i \\frac{x_i}{f} \\left|\\frac{\\partial f}{\\partial x_i}\\right| \\delta x_i.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBAR** como se recuperan las fórmulas anteriores para la suma, resta y multiplicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación de números reales\n",
    "\n",
    "Las computadoras codifican toda la información en binario, es decir, usando dígitos llamados bits, los cuales solo pueden tomar dos valores posibles: 0 o 1. Los números se almacenan como secuencias de bits. En particular, los números reales se representan mediante aritmética de punto flotante.\n",
    "\n",
    "La forma general de un número en punto flotante es:\n",
    "$$\n",
    "\\pm \\, \\text{mantisa} \\times 2^{\\text{exponente}}\n",
    "$$\n",
    "\n",
    "Debido a que una computadora solo puede almacenar un número finito de bits, la representación de los números reales es necesariamente aproximada. Esto introduce un límite conocido como `precisión de máquina`, que corresponde al menor número positivo $\\varepsilon$ tal que\n",
    "$$\n",
    "1 + \\varepsilon \\neq 1\n",
    "$$\n",
    "en la aritmética de la máquina.\n",
    "\n",
    "En el estándar IEEE 754, los números de punto flotante se dividen en dos categorías:\n",
    "- **Números normales**, que utilizan toda la precisión disponible en la mantisa.\n",
    "- **Números subnormales**, que permiten representar números muy cercanos a cero, aunque con menor precisión.\n",
    "\n",
    "Existen varias limitaciones importantes asociadas a la representación en punto flotante:\n",
    "- **Overflow**: ocurre cuando un número es demasiado grande para ser representado.\n",
    "- **Underflow**: ocurre cuando un número es demasiado pequeño y se aproxima a cero.\n",
    "- **Redondeo (rounding)**: ocurre cuando un número real no puede representarse exactamente y debe aproximarse al número representable más cercano.\n",
    "\n",
    "\n",
    " <p align=\"center\"> <img src=\"capturas/1.png\"> </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NOTA`: Aunque los números reales se introducen y se muestran en base 10, Python almacena los números de punto flotante en base 2, siguiendo el estándar IEEE 754."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10000000000000001'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0.1\n",
    "format(x, '.17f')  # error de redondeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10000000000000000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para usar base 10\n",
    "from decimal import Decimal\n",
    "\n",
    "x = Decimal('0.1')\n",
    "format(x, '.17f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En particular, `Python` emplea *doble precisión* para el caso de los números flotantes. En este formato, el almacenamiento ocupa un total de $64$ bits. Esto permite representar números aproximadamente en el rango:\n",
    "\n",
    "$$\n",
    "\\pm 4.9\\times10^{-324} \\;\\; \\leftrightarrow \\;\\; \\pm 1.8\\times 10^{308}.\n",
    "$$\n",
    "\n",
    "El límite inferior corresponde al menor número positivo *subnormal*, mientras que el límite superior es el mayor número finito representable. La mayor parte de este rango dinámico proviene del término asociado al exponente.\n",
    "\n",
    "En el caso de la doble precisión, si se intenta representar un número menor que $4.9\\times10^{-324}$ ocurre un *underflow*, mientras que un número mayor que $1.8\\times 10^{308}$ produce un *overflow*.\n",
    "\n",
    "\\textbf{IMPORTANTE:} El hecho de poder representar números tan pequeños como $4.9\\times10^{-324}$ no implica que se disponga de $324$ cifras significativas. El número de cifras significativas (y, por tanto, la precisión) está determinado por la mantisa.\n",
    "\n",
    "En doble precisión, la mantisa dispone de $52$ bits, lo que implica una precisión relativa de:\n",
    "$$\n",
    "\\varepsilon_{\\text{máquina}} = 2^{-52} \\approx 2.2\\times10^{-16}.\n",
    "$$\n",
    "\n",
    "Esto equivale aproximadamente a $15$–$16$ cifras decimales significativas, independientemente de la magnitud del número representado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base del sistema de representación:  2\n",
      "Dígitos en la mantisa:  53\n",
      "Menor exponente:  -1021\n",
      "Mayor exponente:  1024\n",
      "Menor número positivo normalizado:  2.2250738585072014e-308\n",
      "Mayor número representable:  1.7976931348623157e+308\n",
      "Precisión de máquina:  2.220446049250313e-16\n",
      "Menor exponente en base 10:  -307\n",
      "Mayor exponente en base 10:  308\n",
      "Dígitos en base 10 de la mantisa:  15\n"
     ]
    }
   ],
   "source": [
    "# Info de floats\n",
    "import sys\n",
    "\n",
    "print('Base del sistema de representación: ', sys.float_info.radix)  # base del sistema de representación\n",
    "print('Dígitos en la mantisa: ', sys.float_info.mant_dig)  # dígitos en la mantisa\n",
    "\n",
    "print('Menor exponente: ', sys.float_info.min_exp)  # menor exponente\n",
    "print('Mayor exponente: ', sys.float_info.max_exp)  # mayor exponente\n",
    "\n",
    "print('Menor número positivo normalizado: ', sys.float_info.min)  # menor número positivo normalizado\n",
    "print('Mayor número representable: ', sys.float_info.max)  # mayor número representable\n",
    "print('Precisión de máquina: ', sys.float_info.epsilon)  # precisión de máquina\n",
    "\n",
    "\n",
    "print('Menor exponente en base 10: ', sys.float_info.min_10_exp)  # menor exponente en base 10\n",
    "print('Mayor exponente en base 10: ', sys.float_info.max_10_exp)  # mayor exponente en base 10\n",
    "\n",
    "print('Dígitos en base 10 de la mantisa: ', sys.float_info.dig)  # dígitos en base 10 de la mantisa\n",
    "\n",
    "# sys.float_info  # all info as a named tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-321"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Underflow?\n",
    "x = 1e-320\n",
    "x / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué ocurrió acá?\n",
    "\n",
    "Noten que pude representar un número menor que arrojó `sys.float_info.min`. Lo que ocurre es que lo que arroja es el `mínimo normal`, los  `subnormales` se consideran una extensión del rango, no parte del rango normal\n",
    "\n",
    "Por eso:\n",
    "- min marca el punto donde empieza el underflow gradual\n",
    "- no el valor más pequeño distinto de cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menor número positivo:  5e-324\n"
     ]
    }
   ],
   "source": [
    "print('Menor número positivo: ', sys.float_info.min * sys.float_info.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Underflow\n",
    "x = 1e-324\n",
    "x / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar como cuando ocurre, lo redondea a cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\\times 10^{298} ->  2e+298\n",
      "2\\times 10^{300} ->  2e+300\n",
      "2\\times 10^{302} ->  2e+302\n",
      "2\\times 10^{304} ->  2e+304\n",
      "2\\times 10^{306} ->  2e+306\n",
      "2\\times 10^{308} ->  inf\n"
     ]
    }
   ],
   "source": [
    "# Overflow\n",
    "\n",
    "k = 298\n",
    "for _ in range(6):\n",
    "    large = 2.0 * 10**k\n",
    "    print(r'2\\times 10^{%d} -> ' % k, large)\n",
    "    k += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión de máquina\n",
    "\n",
    "¿Saben qué es la precisión de máquina?\n",
    "\n",
    "La precisión de máquina no está relacionada con los números que podemos representar, sino con la distancia entre dos líneas verticales en la figura anterior. Como se comentó, cualquier número entre estas dos líneas se redondea, ya sea hacia la izquierda o hacia la derecha.\n",
    "\n",
    "Al realizar operaciones aritméticas con dos números de punto flotante, si el resultado no es un número de punto flotante exactamente representable (por ejemplo, 1 y 10 se pueden representar exactamente, pero 1/10 no), entra en juego la precisión de máquina.\n",
    "\n",
    "Pasamos ahora a la cuestión de realizar operaciones aritméticas utilizando tales números: esto da lugar a la importante cuestión del redondeo. Esta situación surge cada vez que intentamos combinar dos números de punto flotante y el resultado no es un número de punto flotante exactamente representable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Ejemplo conceptual`\n",
    "\n",
    "Veamos un ejemplo ficticio para entender mejor. Consideremos que solo podemos almacenar cinco cifras significativas (dígitos). Supongamos que queremos sumar los números $0.12345$ y $1.2345$. Se podría intentar llevarlos a la notación de punto flotante, es decir, $1.2345 = 0.12345 \\times 10^{1}$ mientras que $0.12345 = 0.12345 \\times 10^{0}$. Ahora, en nuestro sistema, estos dos números tendrían la misma mantisa y diferentes exponentes. Sin embargo, para sumar dos mantisas debemos tener el mismo exponente; por ende, esta opción no es viable y debemos realizar la operación como números reales (es decir, no como números decimales de cinco dígitos):\n",
    "\n",
    "\\begin{align}\n",
    "0.12345 + 1.2345 = 1.35795.\n",
    "\\end{align}\n",
    "\n",
    "Ahora, si notan, la respuesta contiene seis cifras significativas, $1.35795$. Dado que estamos limitados a números decimales de cinco dígitos, esto nos deja la opción de truncar el resultado a $1.3579$ o redondearlo a $1.3580$, lo cual nos lleva a perder precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`En resumen`, la precisión de máquina $\\varepsilon_m$ se define como el número positivo más pequeño en punto flotante que, al sumarse a $1.0$, produce un resultado diferente de $1.0$ (al redondearse). Usualmente, para doble precisión se tiene $\\varepsilon_m \\approx 2.2 \\times 10^{-16}$, y para precisión simple $\\varepsilon_m \\approx 1.2 \\times 10^{-7}$.\n",
    "\n",
    "Ejemplo: calculemos la precisión de máquina. Comenzamos con un número pequeño y lo vamos reduciendo a la mitad; después de cada reducción lo sumamos a $1.0$, y repetimos el proceso hasta que eventualmente obtenemos el gap entre números representables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ->  1.0000000000000004 4.440892098500626e-16\n",
      "1  ->  1.0000000000000002 2.220446049250313e-16\n",
      "2  ->  1.0 1.1102230246251565e-16\n",
      "3  ->  1.0 5.551115123125783e-17\n",
      "4  ->  1.0 2.7755575615628914e-17\n"
     ]
    }
   ],
   "source": [
    "# precisión de máquina\n",
    "small = 1/2**50\n",
    "for i in range(5):\n",
    "    small /= 2\n",
    "    print(i, ' -> ', 1+small, small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notese que:\n",
    "\n",
    "-  A partir de la iteración 2, el redondeo no es diferente de $1$, lo que nos da la precisión de máquina.\n",
    "-  Como aún siendo doble precisión (puede almacenar números tan pequeños como $10^{-300}$), no significa que pueda almacenar $1+10^{-300}$ ya que esto necesitarías 301 dígitos de precisión (y todo lo que tienes es 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`La resta`\n",
    "\n",
    "Hagamos un paréntesis y analicemos qué ocurre en una resta:\n",
    "\n",
    "- `la pérdida de cifras significativas al restar dos números casi iguales`;\n",
    "\n",
    "- `la pérdida de aún más dígitos al realizar la resta utilizando números de punto flotante (que tienen precisión finita)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos por el primer caso: \n",
    "\n",
    "Restemos dos números casi iguales, cada uno de los cuales tiene $20$ cifras significativas:\n",
    "\n",
    "\\begin{align}\n",
    "1.2345678912345678912 - 1.2345678900000000000 = 0.0000000012345678912\n",
    "\\end{align}\n",
    "\n",
    "Nótese que, al restar números reales (no representaciones de punto flotante), terminamos con solo $11$ cifras significativas. Es decir, aun trabajando con números reales y precisión infinita, hemos perdido precisión debido a la cancelación entre las cifras comunes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos ahora el segundo caso y utilicemos la representación de punto flotante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.234568003383174e-09"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2345678912345678912 - 1.2345678900000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con la respuesta que teníamos arriba (para números reales), vemos que solo coinciden en las primeras 6 (de 11) cifras significativas. Esto se debe en parte al hecho de que cada uno de nuestras entradas no se representan en el ordenador utilizando las 20 cifras significativas completas, sino sólo 16 dígitos como máximo. \n",
    "\n",
    "Explícitamente, los números almacenados en la máquina son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.234567891234568, 1.23456789)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2345678912345678912, 1.2345678900000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto muestra que ya se pierde precisión en la representación del primer número, lo que posteriormente conduce a una pérdida aún mayor de precisión en el resultado de la resta.\n",
    "\n",
    "\n",
    "Este fenómeno, en el cual la resta de dos números cercanos produce una pérdida significativa de cifras significativas, se conoce como `cancelación catastrófica`. La cancelación ocurre cuando *las cifras más significativas de los operandos coinciden y se eliminan en la resta*, dejando como resultado un número cuyo valor depende principalmente de cifras menos significativas, las cuales son precisamente las más afectadas por los errores de redondeo.\n",
    "\n",
    "*Como consecuencia, aunque los errores relativos en los datos de entrada sean pequeños, el error relativo del resultado puede ser muy grande.* Este efecto no es un problema del computador en sí, sino una característica inherente de la aritmética de punto flotante.\n",
    "\n",
    "Por esta razón, en el diseño de métodos numéricos no solo importa la expresión matemática que se desea evaluar, sino también su forma computacional. Reformulaciones algebraicamente equivalentes pueden presentar comportamientos numéricos muy distintos, y elegir una formulación estable es esencial para obtener resultados fiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando flotantes\n",
    "\n",
    "Dado que sólo cierto números se pueden representar exactamente como flotantes (otros números se redondean al número de máquina más cercano), debemos tener cuidado al comparar números de punto flotante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = 0.1 + 0.2\n",
    "yt = 0.3\n",
    "\n",
    "xt == yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿qué paso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30000000000000004, 0.3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt, yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una posible solución para realizar esta igualdad de variables de punto flotante es tomar el valor absoluto de su diferencia y verificar si esta es menor que algún humbral aceptable por ejemplo: $10^{-10}-10^{-12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(xt-yt) < 1.e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La metodología comentada (denominada *absulute epsilon*) es adecuada en muchas ocasiones donde el \"tamaño\" de los números es \"natural\". Sin embargo, hay situaciones donde puede darnos resultados erroneos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0010013580322265625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = 12345678912.345\n",
    "yt = 12345678912.346\n",
    "print(xt - yt)\n",
    "\n",
    "abs(xt - yt) < 1.e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución para este caso es usar una diferencia relativa (*relative epsilon*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxFin = lambda x, y: max(abs(x), abs(y))\n",
    "\n",
    "abs(xt - yt)/maxFin(xt, yt) < 1.e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma compensada\n",
    "\n",
    "Pasamos ahora a una cuestión crucial relativa a las operaciones con números de punto flotante. En resumen, debido a los errores de redondeo, cuando se trabaja con aritmética de punto flotante, `la ley asociativa del álgebra` no necesariamente se cumple.\n",
    "\n",
    "Usted sabe que, matemáticamente,\n",
    "\\begin{align}\n",
    "0.1 + 0.2 = 0.3\n",
    "\\end{align}\n",
    "\n",
    "Sin embargo, cuando se utilizan números de punto flotante, el resultado de una suma puede depender del orden en que se realizan las operaciones, debido a los errores de redondeo introducidos en cada paso.\n",
    "\n",
    "Veamos un ejemplo sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado de: (0.7 + 0.1) + 0.3 = 1.0999999999999999\n",
      "Resultado de:  0.7 + (0.1 + 0.3) = 1.1\n"
     ]
    }
   ],
   "source": [
    "print(f'Resultado de: (0.7 + 0.1) + 0.3 = {(0.7 + 0.1) + 0.3}')\n",
    "print(f'Resultado de:  0.7 + (0.1 + 0.3) = {0.7 + (0.1 + 0.3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque ambas expresiones son algebraicamente equivalentes, los resultados difieren ligeramente debido a la acumulación de errores de redondeo. Esto muestra que, `en aritmética de punto flotante, la suma no es asociativa`.\n",
    "\n",
    "Este problema se vuelve especialmente relevante al sumar una gran cantidad de números, `en particular cuando existen números de magnitudes muy distintas`. En tales casos, los errores de redondeo pueden acumularse y provocar una pérdida significativa de precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este ejemplo queda claro que operaciones que son equivalentes en números reales pueden no serlo si se usan flotantes. Este ejemplo no es atípico, de hecho, puede ocurrír más drástico:\n",
    "\n",
    "\\begin{align}\n",
    "    (10^{20} - 10^{20}) + 1 \\neq 10^{20} + (1 - 10^{20})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "xt = 1.e20\n",
    "yt = -1.e20\n",
    "zt = 1.\n",
    "\n",
    "res1 = (xt + yt) + zt\n",
    "res2 = xt + (yt + zt)\n",
    "\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En el primer caso, los dos números grandes, `xt`, `yt`, se cancelan entre sí y nos queda la unidad como respuesta. \n",
    "\n",
    "- En el segundo caso, nos enfrentamos a una situación similar a la discutida en la precisión de máquina, sumar $1$ al número grande (negativo) `yt`, simplemente se redondea a `yt`, luego, se cancela con `xt`.\n",
    "\n",
    "    El **error garrafal** viene del hecho de estar trabajando con magnitudes muy diferentes (muy grandes y muy pequeños) y con signos opuestos. Uno podría decir entonces que cuando esto ocurre no se puede confiar en el resultado numérico. Sin embargo, en muchas ocasiones no somos concientes de que esto ocurre (ya que puede aparecer internamente en operaciones intermedias). En tal sentido `la lección es que uno debe acostumbrarse a razonar sobre sus cálculos, en lugar de confiar ciegamente en lo que produce la computadora`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Para mitigar este efecto, se han desarrollado técnicas como la suma compensada, cuyo objetivo es reducir el error de redondeo acumulado durante la suma de muchos términos.\n",
    "\n",
    "A continuación veamos como podemos intentar resolver estos problemas. Una manera de evitar estos errores de redondeo es `ordenar los números y luego sumarlos comenzando por el más pequeño`. Sin embargo, hay escenarios en que esto no es viable, en estos casos se emplea un truco llamado `suma compensada` o `suma Kahan`. Este truco lo que hace es estimar el error de redondeo en cada suma y luego compensarlo con un término de corrección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el algoritmo de Kahan lLa idea central es llevar un registro explícito del error de redondeo que se introduce en cada suma, y compensarlo en las operaciones posteriores.\n",
    "\n",
    "`Idea básica del algoritmo:`\n",
    "\n",
    "Supongamos que queremos calcular la suma:\n",
    "\\begin{align}\n",
    "S = \\sum_{i=1}^{n} x_i.\n",
    "\\end{align}\n",
    "\n",
    "En la suma directa, cada operación de suma introduce un pequeño error de redondeo que se pierde inmediatamente. En la suma compensada, se introduce una variable adicional que acumula estos errores perdidos y los reincorpora en los pasos siguientes.\n",
    "\n",
    "De manera esquemática, el algoritmo mantiene dos variables:\n",
    "- una suma acumulada,\n",
    "\n",
    "- un término de compensación que almacena el error de redondeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0999999999999999 1.1\n"
     ]
    }
   ],
   "source": [
    "def kahansum(lis):\n",
    "    suma, compensacion = 0., 0.\n",
    "    for x in lis:\n",
    "        y = x - compensacion\n",
    "        temp = suma + y\n",
    "        compensacion = (temp - suma) - y\n",
    "        suma = temp\n",
    "    return suma\n",
    "\n",
    "lis = [0.7, 0.1, 0.3]\n",
    "print(sum(lis), kahansum(lis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de Kahan requiere más cálculos que la suma regular lo cual penaliza el rendimiento y además `no elimina el error de redondeo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando expresiones\n",
    "\n",
    "A continuación se discutirá como es posible perder precisión como consecuencia de la forma en que se escriben las ecuaciones. Por ejemplo consideremos:\n",
    "$$f(x)=\\frac{1}{\\sqrt{x^2+1}-x}$$\n",
    "\n",
    "para valores grandes de $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -> 19999.99977764674\n",
      "100000 -> 200000.22333140278\n",
      "1000000 -> 1999984.77112922\n",
      "10000000 -> 19884107.85185185\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "f = lambda x: 1/(np.sqrt(x**2+1)-x)\n",
    "\n",
    "xs = [10**i for i in range(4, 8)]\n",
    "ys = [f(i) for i in xs]\n",
    "\n",
    "for x, y in zip(xs, ys):\n",
    "    print(x, '->',  y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten como el resultado parece empeorar cada vez más a medida que aumenta el valor de x. Una manera de verlo es considerando $x=10^{8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/vfyq6zyn4l35gfd2kgq4k2q00000gn/T/ipykernel_81836/577568385.py:2: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f = lambda x: 1/(np.sqrt(x**2+1)-x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sucede porque para valores grandes de $x$, sabemos que $x + 1 \\approx x$, lo que implica que necesitemos evaluar la raíz cuadrada con mucha precisión si quiero poder restarle un número casi igual.\n",
    "\n",
    "Una forma sencilla de evitar este problema consiste en reescribir la expresión inicial como:\n",
    "$$ f(x)=\\sqrt{x^2+1}+x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -> 20000.000050000002\n",
      "100000 -> 200000.00000499998\n",
      "1000000 -> 2000000.0000005001\n",
      "10000000 -> 20000000.000000052\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "f = lambda x: np.sqrt(x**2+1)+x\n",
    "\n",
    "xs = [10**i for i in range(4, 8)]\n",
    "ys = [f(i) for i in xs]\n",
    "\n",
    "for x, y in zip(xs, ys):\n",
    "    print(x, '->',  y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten como mejoró. De hecho, como se aprecia de la ecuación para $x$ grandes la función se comporta como $2x$. \n",
    "\n",
    "Resumiendo, en muchas ocasiones una simple reescritura de la expresión inicial puede evitar problemas de precisión numérica (a menudo evitando una resta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea:\n",
    "1- \n",
    "\n",
    "<img src=\"capturas/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-\n",
    "\n",
    "<img src=\"capturas/3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
